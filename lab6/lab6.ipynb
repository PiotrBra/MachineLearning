{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "216c5138bd9cbe51",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "Autor: Piotr Branewski"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a35322aa178cf9",
   "metadata": {},
   "source": [
    "## Założenia i cel\n",
    "1. Załóżmy, że jesteśmy w stanie zaetykietować x% (np.. 5%) zbioru danych określając ich przynależność do K klas. Zbiór danych proszę wybrać dowolny (najlepiej jednak zrobić to na 2 zbiorach danych.\n",
    "2. CEL: Zaetykietuj resztę obiektów elementów danych wykorzystując metody klasteryzacji\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7b4ae000e3751e",
   "metadata": {},
   "source": [
    "## Zadanie - szczegóły\n",
    "1. Poprzez klasteryzację zbioru na C klastrów „zgadnij” jak największą liczbę etykiet. Wybierz odpowiednio „silny” algorytm klasteryzacji. Wykorzystaj Clustering — scikit-learn 1.2.2 documentation i zamieszczony na Teams wykład. Możesz posłużyć się podziałem grafu najbliższych sąsiadów (graph cut and partition).\n",
    "2. Na odgadniętych etykietach (i tych wcześniej znanych – zbiór treningowy) naucz sieć (także jej architektura może być dowolna) rozpoznawać klasy.\n",
    "3. Dane bez odgadniętych etykiet użyj jako zbiór testowy. \n",
    "4. Powtórz 1-3 kilka razy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceb1a21-77c5-4cba-822a-6f7c393c0a06",
   "metadata": {},
   "source": [
    "### import bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T09:31:27.338497Z",
     "start_time": "2025-06-10T09:31:27.259819Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.datasets import load_iris, load_wine\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "\n",
    "# Wyłączamy ostrzeżenia, aby notebook był czytelniejszy\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e4167d8e032d59",
   "metadata": {},
   "source": [
    " ### Implementacja Pojedynczego Eksperymentu Pół-nadzorowanego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32d21fe6750a8220",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T09:18:23.082827Z",
     "start_time": "2025-06-10T09:18:12.147574Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_semi_supervised(X, y, C=3, label_pct=0.05, seed=0):\n",
    "    \"\"\"\n",
    "    Przeprowadza pojedynczy eksperyment uczenia pół-nadzorowanego:\n",
    "    1. Losuje 'label_pct'% oznaczonych przykładów.\n",
    "    2. Dzieli pozostałe dane na zbiory 'guess' i 'test'.\n",
    "    3. Etykietuje klastry na podstawie głosowania większości znanego punktu.\n",
    "    4. Trenuje klasyfikator MLP i zwraca dokładność na zbiorze testowym.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = X.shape[0]\n",
    "    n_lab = int(label_pct * n)\n",
    "\n",
    "    idx_all = np.arange(n)\n",
    "    idx_lab = rng.choice(idx_all, n_lab, replace=False)\n",
    "    idx_unlab = np.setdiff1d(idx_all, idx_lab)\n",
    "\n",
    "    rng.shuffle(idx_unlab)\n",
    "    split = len(idx_unlab) // 2\n",
    "    idx_guess, idx_test = idx_unlab[:split], idx_unlab[split:]\n",
    "\n",
    "    # Klasteryzacja na całym zbiorze X\n",
    "    clust = SpectralClustering(\n",
    "        n_clusters=C, affinity=\"nearest_neighbors\",\n",
    "        n_neighbors=10, random_state=seed\n",
    "    )\n",
    "    clusters = clust.fit_predict(X)\n",
    "\n",
    "    # Mapowanie klaster -> klasa na podstawie znanych etykiet (majority vote)\n",
    "    cl2class = {}\n",
    "    for c in range(C):\n",
    "        members = np.where(clusters == c)[0]\n",
    "        known = np.intersect1d(members, idx_lab)\n",
    "        cl2class[c] = (\n",
    "            Counter(y[known]).most_common(1)[0][0] if known.size else -1\n",
    "        )\n",
    "\n",
    "    # Budowanie pseudo-etykiet dla unlabeled_guess_idx\n",
    "    y_pseudo = np.ones_like(y) * -1 # Domyślnie 'brak etykiety'\n",
    "    for i in idx_guess:\n",
    "        cluster_label = clusters[i]\n",
    "        if cl2class[cluster_label] != -1:\n",
    "            y_pseudo[i] = cl2class[cluster_label]\n",
    "\n",
    "    # Przygotowanie zbiorów treningowych i testowych\n",
    "    train_mask = np.isin(idx_all, idx_lab) | (\n",
    "        np.isin(idx_all, idx_guess) & (y_pseudo != -1)\n",
    "    )\n",
    "    \n",
    "    X_train = X[train_mask]\n",
    "    # Jeśli y_pseudo jest -1, używamy y_true (dla oryginalnych 5% etykiet), w przeciwnym razie pseudo-etykietę\n",
    "    y_train = np.where(y_pseudo[train_mask] != -1, y_pseudo[train_mask], y[train_mask])\n",
    "\n",
    "    X_test = X[idx_test]\n",
    "    y_test = y[idx_test]\n",
    "\n",
    "    # Trenowanie klasyfikatora MLP\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(50,), max_iter=300, random_state=seed)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    acc = accuracy_score(y_test, clf.predict(X_test))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968652ff35632731",
   "metadata": {},
   "source": [
    "### Funkcja do Wielokrotnych Przebiegów i Wariacji "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cadbe84926d8f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T09:25:53.946086Z",
     "start_time": "2025-06-10T09:22:14.976872Z"
    }
   },
   "outputs": [],
   "source": [
    "def sweep_C_and_repeats(X, y, C_list=(2, 3, 4, 5), repeats=10):\n",
    "    \"\"\"\n",
    "    Przeprowadza wielokrotne eksperymenty dla różnych wartości C (liczby klastrów)\n",
    "    i zwraca średnią dokładność oraz odchylenie standardowe.\n",
    "    \"\"\"\n",
    "    results = {C: [] for C in C_list}\n",
    "    for C in C_list:\n",
    "        for rep in range(repeats):\n",
    "            acc = run_semi_supervised(X, y, C=C, seed=rep)\n",
    "            results[C].append(acc)\n",
    "    return {C: (np.mean(a), np.std(a)) for C, a in results.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68e74f9e637c0ff",
   "metadata": {},
   "source": [
    "### Przeprowadzenie Eksperymentów dla Iris i Wine (Pół-nadzorowane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71940a6b062f81fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T09:25:53.991593900Z",
     "start_time": "2025-06-10T09:13:46.752472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wyniki dla zbioru Iris (Pół-nadzorowane): {2: (np.float64(0.5527777777777778), np.float64(0.18308063392537868)), 3: (np.float64(0.7625), np.float64(0.21113395344258654)), 4: (np.float64(0.7236111111111111), np.float64(0.2027444797622714)), 5: (np.float64(0.725), np.float64(0.20134578082689025))}\n",
      "Wyniki dla zbioru Wine (Pół-nadzorowane): {2: (np.float64(0.3823529411764706), np.float64(0.14525958151103577)), 3: (np.float64(0.36235294117647054), np.float64(0.10172219445278721)), 4: (np.float64(0.36941176470588233), np.float64(0.12194502136329353)), 5: (np.float64(0.38235294117647056), np.float64(0.12954538556203082))}\n"
     ]
    }
   ],
   "source": [
    "# Wczytanie danych\n",
    "X_iris, y_iris = load_iris(return_X_y=True)\n",
    "X_wine, y_wine = load_wine(return_X_y=True)\n",
    "\n",
    "# Uruchomienie eksperymentów pół-nadzorowanych\n",
    "iris_res = sweep_C_and_repeats(X_iris, y_iris)\n",
    "wine_res = sweep_C_and_repeats(X_wine, y_wine)\n",
    "\n",
    "print(\"Wyniki dla zbioru Iris (Pół-nadzorowane):\", iris_res)\n",
    "print(\"Wyniki dla zbioru Wine (Pół-nadzorowane):\", wine_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fdc4a2e6de5464",
   "metadata": {},
   "source": [
    "### Implementacja Linii Bazowej (W pełni nadzorowane z 5% danych)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a83b5f5a4e198de3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T09:25:53.992591700Z",
     "start_time": "2025-06-10T09:14:06.537014Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def baseline_supervised(X, y, label_pct=0.05, seed=0):\n",
    "    \"\"\"\n",
    "    Uczenie w pełni nadzorowane, wykorzystujące tylko 'label_pct'% danych.\n",
    "    Służy jako punkt odniesienia.\n",
    "    \"\"\"\n",
    "    # Dzielimy dane na zbiory treningowy i testowy. Zbiór treningowy ma tylko label_pct% danych.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=1 - label_pct, stratify=y, random_state=seed\n",
    "    )\n",
    "\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(50,), max_iter=300, random_state=seed)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    return accuracy_score(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e6d796-da23-495b-a2e3-438b1628703f",
   "metadata": {},
   "source": [
    "### Funkcja Podsumowująca Wyniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7795883-145c-4337-94a4-1b7344d3b1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_results(semi_supervised_results, full_supervised_results):\n",
    "    \"\"\"\n",
    "    Generuje tabelę podsumowującą wyniki dla trybu pół-nadzorowanego (najlepsze C)\n",
    "    i trybu w pełni nadzorowanego (dla 5% danych).\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    # Wyniki dla trybu pół-nadzorowanego\n",
    "    best_C = max(semi_supervised_results, key=lambda c: semi_supervised_results[c][0])\n",
    "    rows.append([\n",
    "        \"Pół-nadzorowane (najlepsze C)\", best_C,\n",
    "        *map(lambda x: round(x, 3), semi_supervised_results[best_C])\n",
    "    ])\n",
    "\n",
    "    # Wyniki dla trybu w pełni nadzorowanego\n",
    "    rows.append([\n",
    "        \"W pełni nadzorowane (5%)\", \"-\",\n",
    "        round(np.mean(full_supervised_results), 3), round(np.std(full_supervised_results), 3)\n",
    "    ])\n",
    "    \n",
    "    return rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356b770e-456d-4745-9a01-f2bdde415777",
   "metadata": {},
   "source": [
    "### Obliczenie Linii Bazowych i Wyświetlenie Wyników"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d2eb942-de26-4c75-a928-cee199dec9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Wyniki dla zbioru: Iris\n",
      "| Tryb                          | C   |   Średnia dokładność |   Odchylenie std |\n",
      "|:------------------------------|:----|---------------------:|-----------------:|\n",
      "| Pół-nadzorowane (najlepsze C) | 3   |                0.762 |            0.211 |\n",
      "| W pełni nadzorowane (5%)      | -   |                0.901 |            0.052 |\n",
      "\n",
      " Wyniki dla zbioru: Wine\n",
      "| Tryb                          | C   |   Średnia dokładność |   Odchylenie std |\n",
      "|:------------------------------|:----|---------------------:|-----------------:|\n",
      "| Pół-nadzorowane (najlepsze C) | 2   |                0.382 |            0.145 |\n",
      "| W pełni nadzorowane (5%)      | -   |                0.388 |            0.126 |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # Dodaj ten import na początku notebooka, jeśli jeszcze go nie ma\n",
    "\n",
    "# Obliczenie wyników dla linii bazowej (w pełni nadzorowane z 5% danych)\n",
    "iris_baseline = [baseline_supervised(X_iris, y_iris, seed=s) for s in range(10)]\n",
    "wine_baseline = [baseline_supervised(X_wine, y_wine, seed=s) for s in range(10)]\n",
    "\n",
    "# Podsumowanie i przygotowanie danych dla tabel\n",
    "iris_table_data = summarize_results(iris_res, iris_baseline)\n",
    "wine_table_data = summarize_results(wine_res, wine_baseline)\n",
    "\n",
    "# Definicja nagłówków kolumn\n",
    "headers = [\"Tryb\", \"C\", \"Średnia dokładność\", \"Odchylenie std\"]\n",
    "\n",
    "# Tworzenie i wyświetlanie tabel dla Iris\n",
    "print(\"\\n Wyniki dla zbioru: Iris\")\n",
    "df_iris = pd.DataFrame(iris_table_data, columns=headers)\n",
    "print(df_iris.to_markdown(index=False)) # Używamy to_markdown dla łatwego kopiowania i wklejania w markdown\n",
    "\n",
    "# Tworzenie i wyświetlanie tabel dla Wine\n",
    "print(\"\\n Wyniki dla zbioru: Wine\")\n",
    "df_wine = pd.DataFrame(wine_table_data, columns=headers)\n",
    "print(df_wine.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778cd563-9b44-426c-b2b3-5fa925af59dd",
   "metadata": {},
   "source": [
    "### analiza wyników"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e884b99-7fcb-43f2-9c2c-b31e77432fab",
   "metadata": {},
   "source": [
    "**Konfiguracja MLP:**\n",
    "\n",
    "- Warstwa ukryta: 50 neuronów z funkcją aktywacji ReLU.\n",
    "- Optymalizator: Adam, współczynnik uczenia lr=0.001.\n",
    "- Maksymalna liczba iteracji: 300.\n",
    "- Funkcja straty: entropia krzyżowa.\n",
    "\n",
    "\n",
    "**Zbiór danych Iris:**\n",
    "* Najlepszą wydajność w scenariuszu pół-nadzorowanym osiągnęliśmy dla $C=3$, co jest zgodne z rzeczywistą liczbą klas w zbiorze Iris.\n",
    "* Obserwujemy znaczną różnicę w dokładności (~14 punktów procentowych) w porównaniu do modelu trenowanego wyłącznie na prawdziwych 5% etykietowanych danych.\n",
    "* Duże odchylenie standardowe ($\\sigma \\approx 0.21$) wskazuje na brak stabilności. Oznacza to, że wyniki są bardzo wrażliwe na konkretny wybór początkowych 5% etykietowanych próbek oraz na sposób, w jaki klasteryzacja Spectral Clustering dzieli dane.\n",
    "* Wniosek: Jakość generowanych pseudo-etykiet jest niejednolita; ponieważ Iris jest małym zbiorem danych, każdy błąd w przypisaniu etykiety ma duży wpływ na końcową dokładność.\n",
    "\n",
    "**Zbiór danych Wine:**\n",
    "* Co zaskakujące, najwyższą dokładność w trybie pół-nadzorowanym uzyskaliśmy dla $C=2$ , co sugeruje, że Spectral Clustering miał trudności z identyfikacją trzech faktycznych typów wina.\n",
    "* Tryb pół-nadzorowany praktycznie nie przynosi zysku w porównaniu do linii bazowej (0.382 vs 0.388); mamy szum, ale zero wartości dodanej.\n",
    "* Podejrzewamy, że wysoka, 13-wymiarowa przestrzeń cech w połączeniu z niewielką liczbą ręcznie etykietowanych próbek skutkuje niską jakością macierzy sąsiedztwa, co negatywnie wpływa na klasteryzację i uniemożliwia prawidłowe rozpoznanie naturalnych klas.\n",
    "\n",
    "**Ogólne wnioski:**\n",
    "Przy 5% ręcznego etykietowania, **bardziej opłacalne jest często trenowanie sieci w trybie w pełni nadzorowanym** niż próba \"doklejania\" ryzykownych pseudo-etykiet.\n",
    "\n",
    "### Potencjalne Ulepszenia:\n",
    "* **Redukcja wymiarowości:** Zastosowanie technik takich jak PCA lub t-SNE przed klasteryzacją.\n",
    "* **Zmiana algorytmu klasteryzacji:** Eksperymentowanie z innymi algorytmami, np.DBSCAN, HDBSCAN, lub dokładne dostrojenie parametrów k-NN dla Spectral Clustering.\n",
    "* **Zwiększenie odsetka ręcznie etykietowanych próbek:** Podniesienie tej wartości (np. do 10%) może znacząco poprawić jakość klastrów i stabilność modelu."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
